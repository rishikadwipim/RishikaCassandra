{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "be14226f",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from cassandra.cluster import Cluster\n",
    "from cassandra.auth import PlainTextAuthProvider\n",
    "from cassandra.query import SimpleStatement\n",
    "import json\n",
    "from datetime import datetime"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "1cb6e232",
   "metadata": {},
   "outputs": [],
   "source": [
    "def establish_cassandra_connection():\n",
    "    \"\"\"\n",
    "    Establishes a secure connection to the Cassandra database using credentials and a secure connect bundle.\n",
    "    \"\"\"\n",
    "    config = {'secure_connect_bundle': 'secure-connect-rishikadwipi.zip'}\n",
    "\n",
    "    # Load secrets from JSON file\n",
    "    with open(\"rishikadwipi-token.json\", \"r\") as secret_file:\n",
    "        credentials = json.load(secret_file)\n",
    "\n",
    "    auth_provider = PlainTextAuthProvider(credentials[\"clientId\"], credentials[\"secret\"])\n",
    "    cluster = Cluster(cloud=config, auth_provider=auth_provider)\n",
    "    session = cluster.connect()\n",
    "    return session, cluster"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "8b15a451",
   "metadata": {},
   "outputs": [],
   "source": [
    "def upload_raw_data(session, keyspace, table_name, data_frame):\n",
    "    \"\"\"\n",
    "    Creates a table in Cassandra and inserts the raw data from the provided DataFrame.\n",
    "    \"\"\"\n",
    "    # Define table structure\n",
    "    create_table_stmt = f\"\"\"\n",
    "    CREATE TABLE IF NOT EXISTS {keyspace}.{table_name} (\n",
    "        region TEXT,\n",
    "        country TEXT,\n",
    "        itemtype TEXT,\n",
    "        saleschannel TEXT,\n",
    "        orderpriority TEXT,\n",
    "        orderdate TEXT,\n",
    "        orderid BIGINT PRIMARY KEY,\n",
    "        shipdate TEXT,\n",
    "        unitssold INT,\n",
    "        unitprice FLOAT,\n",
    "        unitcost FLOAT,\n",
    "        totalrevenue FLOAT,\n",
    "        totalcost FLOAT,\n",
    "        totalprofit FLOAT\n",
    "    )\n",
    "    \"\"\"\n",
    "    session.execute(create_table_stmt)\n",
    "\n",
    "    # Prepare an insert statement\n",
    "    insert_stmt = session.prepare(f\"\"\"\n",
    "    INSERT INTO {keyspace}.{table_name} (\n",
    "        region, country, itemtype, saleschannel, orderpriority,\n",
    "        orderdate, orderid, shipdate, unitssold, unitprice,\n",
    "        unitcost, totalrevenue, totalcost, totalprofit\n",
    "    ) VALUES (?, ?, ?, ?, ?, ?, ?, ?, ?, ?, ?, ?, ?, ?)\n",
    "    \"\"\")\n",
    "    \n",
    "    for _, row in data_frame.iterrows():\n",
    "        session.execute(insert_stmt, (\n",
    "            row['Region'], row['Country'], row['Item Type'], row['Sales Channel'],\n",
    "            row['Order Priority'], row['Order Date'], row['Order ID'], row['Ship Date'],\n",
    "            row['UnitsSold'], row['UnitPrice'], row['UnitCost'],\n",
    "            row['TotalRevenue'], row['TotalCost'], row['TotalProfit']\n",
    "        ))\n",
    "    print(\"Raw data uploaded!!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "a04ac630",
   "metadata": {},
   "outputs": [],
   "source": [
    "def clean_bronze_data(raw_data_frame):\n",
    "    \"\"\"\n",
    "    Cleans raw data from the bronze stage and prepares it for the silver stage.\n",
    "    \"\"\"\n",
    "    # Drop rows with missing critical fields\n",
    "    important_cols = [\n",
    "        \"region\", \"country\", \"itemtype\", \"saleschannel\", \n",
    "        \"orderpriority\", \"orderdate\", \"orderid\", \"shipdate\"\n",
    "    ]\n",
    "    cleaned_df = raw_data_frame.dropna(subset=important_cols)\n",
    "\n",
    "    # Convert data types\n",
    "    type_conversions = {\n",
    "        \"orderid\": int,\n",
    "        \"unitssold\": int,\n",
    "        \"unitprice\": float,\n",
    "        \"unitcost\": float,\n",
    "        \"totalrevenue\": float,\n",
    "        \"totalcost\": float,\n",
    "        \"totalprofit\": float\n",
    "    }\n",
    "    for col, dtype in type_conversions.items():\n",
    "        cleaned_df[col] = cleaned_df[col].astype(dtype)\n",
    "\n",
    "    # Standardize date formats\n",
    "    date_format = \"%m/%d/%Y\"\n",
    "    cleaned_df[\"orderdate\"] = pd.to_datetime(cleaned_df[\"orderdate\"], format=date_format, errors=\"coerce\")\n",
    "    cleaned_df[\"shipdate\"] = pd.to_datetime(cleaned_df[\"shipdate\"], format=date_format, errors=\"coerce\")\n",
    "\n",
    "    # Drop rows with invalid dates\n",
    "    cleaned_df = cleaned_df.dropna(subset=[\"orderdate\", \"shipdate\"])\n",
    "\n",
    "    # Lowercase for categorical fields\n",
    "    categorical_fields = [\"region\", \"country\", \"itemtype\", \"saleschannel\", \"orderpriority\"]\n",
    "    for field in categorical_fields:\n",
    "        cleaned_df[field] = cleaned_df[field].str.lower()\n",
    "\n",
    "    # Validate logical constraints (e.g., orderdate <= shipdate)\n",
    "    cleaned_df = cleaned_df[cleaned_df[\"orderdate\"] <= cleaned_df[\"shipdate\"]]\n",
    "\n",
    "    # Add a timestamp for data processing\n",
    "    cleaned_df[\"processed_at\"] = datetime.now()\n",
    "\n",
    "    return cleaned_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "ecdfa778",
   "metadata": {},
   "outputs": [],
   "source": [
    "def save_silver_data(session, keyspace, table_name, silver_df):\n",
    "    \"\"\"\n",
    "    Saves the cleaned data (silver stage) into Cassandra.\n",
    "    \"\"\"\n",
    "    # Create the silver table\n",
    "    create_stmt = f\"\"\"\n",
    "    CREATE TABLE IF NOT EXISTS {keyspace}.{table_name} (\n",
    "        orderid BIGINT PRIMARY KEY,\n",
    "        country TEXT,\n",
    "        itemtype TEXT,\n",
    "        orderdate DATE,\n",
    "        orderpriority TEXT,\n",
    "        region TEXT,\n",
    "        saleschannel TEXT,\n",
    "        shipdate DATE,\n",
    "        totalcost FLOAT,\n",
    "        totalprofit FLOAT,\n",
    "        totalrevenue FLOAT,\n",
    "        unitcost FLOAT,\n",
    "        unitprice FLOAT,\n",
    "        unitssold INT,\n",
    "        processed_at TIMESTAMP\n",
    "    );\n",
    "    \"\"\"\n",
    "    session.execute(create_stmt)\n",
    "\n",
    "    # Insert cleaned data\n",
    "    insert_stmt = session.prepare(f\"\"\"\n",
    "    INSERT INTO {keyspace}.{table_name} (\n",
    "        orderid, country, itemtype, orderdate, orderpriority, region, \n",
    "        saleschannel, shipdate, totalcost, totalprofit, totalrevenue, \n",
    "        unitcost, unitprice, unitssold, processed_at\n",
    "    ) VALUES (?, ?, ?, ?, ?, ?, ?, ?, ?, ?, ?, ?, ?, ?, ?)\n",
    "    \"\"\")\n",
    "    \n",
    "    for _, row in silver_df.iterrows():\n",
    "        session.execute(insert_stmt, (\n",
    "            row[\"orderid\"], row[\"country\"], row[\"itemtype\"], row[\"orderdate\"].date(),\n",
    "            row[\"orderpriority\"], row[\"region\"], row[\"saleschannel\"], row[\"shipdate\"].date(),\n",
    "            row[\"totalcost\"], row[\"totalprofit\"], row[\"totalrevenue\"],\n",
    "            row[\"unitcost\"], row[\"unitprice\"], row[\"unitssold\"], row[\"processed_at\"]\n",
    "        ))\n",
    "\n",
    "    print(\"Silver data uploaded successfully!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "2cd3cbed",
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_gold_tables(session, keyspace, silver_table):\n",
    "    \"\"\"\n",
    "    Creates three gold tables in Cassandra with aggregated data.\n",
    "    \"\"\"\n",
    "    # Load data from the silver table\n",
    "    query = f\"SELECT * FROM {keyspace}.{silver_table}\"\n",
    "    rows = session.execute(query)\n",
    "    silver_df = pd.DataFrame([row._asdict() for row in rows])\n",
    "\n",
    "    # 1. Total Sales by Region\n",
    "    total_sales_by_region = silver_df.groupby(\"region\").agg(\n",
    "        total_revenue=pd.NamedAgg(column=\"totalrevenue\", aggfunc=\"sum\"),\n",
    "        total_cost=pd.NamedAgg(column=\"totalcost\", aggfunc=\"sum\"),\n",
    "        total_profit=pd.NamedAgg(column=\"totalprofit\", aggfunc=\"sum\")\n",
    "    ).reset_index()\n",
    "\n",
    "    create_region_table = f\"\"\"\n",
    "    CREATE TABLE IF NOT EXISTS {keyspace}.gold_sales_by_region (\n",
    "        region TEXT PRIMARY KEY,\n",
    "        total_revenue FLOAT,\n",
    "        total_cost FLOAT,\n",
    "        total_profit FLOAT\n",
    "    )\n",
    "    \"\"\"\n",
    "    session.execute(create_region_table)\n",
    "\n",
    "    insert_region = session.prepare(f\"\"\"\n",
    "    INSERT INTO {keyspace}.gold_sales_by_region (region, total_revenue, total_cost, total_profit)\n",
    "    VALUES (?, ?, ?, ?)\n",
    "    \"\"\")\n",
    "\n",
    "    for _, row in total_sales_by_region.iterrows():\n",
    "        session.execute(insert_region, (row[\"region\"], row[\"total_revenue\"], row[\"total_cost\"], row[\"total_profit\"]))\n",
    "\n",
    "    print(\"Gold table: Total Sales by Region uploaded successfully!\")\n",
    "\n",
    "    # 2. Top-Selling Items by Item Type\n",
    "    top_items_by_type = silver_df.groupby(\"itemtype\").agg(\n",
    "        total_units_sold=pd.NamedAgg(column=\"unitssold\", aggfunc=\"sum\")\n",
    "    ).reset_index()\n",
    "\n",
    "    create_item_table = f\"\"\"\n",
    "    CREATE TABLE IF NOT EXISTS {keyspace}.gold_top_items_by_type (\n",
    "        itemtype TEXT PRIMARY KEY,\n",
    "        total_units_sold INT\n",
    "    )\n",
    "    \"\"\"\n",
    "    session.execute(create_item_table)\n",
    "\n",
    "    insert_item = session.prepare(f\"\"\"\n",
    "    INSERT INTO {keyspace}.gold_top_items_by_type (itemtype, total_units_sold)\n",
    "    VALUES (?, ?)\n",
    "    \"\"\")\n",
    "\n",
    "    for _, row in top_items_by_type.iterrows():\n",
    "        session.execute(insert_item, (row[\"itemtype\"], row[\"total_units_sold\"]))\n",
    "\n",
    "    print(\"Gold table: Top-Selling Items by Item Type uploaded successfully!\")\n",
    "\n",
    "    # 3. Sales Performance by Country\n",
    "    sales_performance_by_country = silver_df.groupby(\"country\").agg(\n",
    "        total_revenue=pd.NamedAgg(column=\"totalrevenue\", aggfunc=\"sum\"),\n",
    "        total_profit=pd.NamedAgg(column=\"totalprofit\", aggfunc=\"sum\")\n",
    "    ).reset_index()\n",
    "\n",
    "    create_country_table = f\"\"\"\n",
    "    CREATE TABLE IF NOT EXISTS {keyspace}.gold_sales_by_country (\n",
    "        country TEXT PRIMARY KEY,\n",
    "        total_revenue FLOAT,\n",
    "        total_profit FLOAT\n",
    "    )\n",
    "    \"\"\"\n",
    "    session.execute(create_country_table)\n",
    "\n",
    "    insert_country = session.prepare(f\"\"\"\n",
    "    INSERT INTO {keyspace}.gold_sales_by_country (country, total_revenue, total_profit)\n",
    "    VALUES (?, ?, ?)\n",
    "    \"\"\")\n",
    "\n",
    "    for _, row in sales_performance_by_country.iterrows():\n",
    "        session.execute(insert_country, (row[\"country\"], row[\"total_revenue\"], row[\"total_profit\"]))\n",
    "\n",
    "    print(\"Gold table: Sales Performance by Country uploaded successfully!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "49f5b564",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Raw data uploaded!!\n",
      "Silver data uploaded successfully!\n",
      "Gold table: Total Sales by Region uploaded successfully!\n",
      "Gold table: Top-Selling Items by Item Type uploaded successfully!\n",
      "Gold table: Sales Performance by Country uploaded successfully!\n"
     ]
    }
   ],
   "source": [
    "if __name__ == \"__main__\":\n",
    "    # Establish connection\n",
    "    session, cluster = establish_cassandra_connection()\n",
    "    keyspace = 'cs'\n",
    "\n",
    "    # Load raw data\n",
    "    raw_data = pd.read_csv(\"https://raw.githubusercontent.com/gchandra10/filestorage/main/sales_100.csv\")\n",
    "    bronze_table = 'bronze_sales'\n",
    "    upload_raw_data(session, keyspace, bronze_table, raw_data)\n",
    "\n",
    "    # Extract raw data from Cassandra\n",
    "    query_stmt = f\"SELECT * FROM {keyspace}.{bronze_table}\"\n",
    "    raw_rows = session.execute(query_stmt)\n",
    "    bronze_df = pd.DataFrame([row._asdict() for row in raw_rows])\n",
    "\n",
    "    # Clean data for silver stage\n",
    "    silver_df = clean_bronze_data(bronze_df)\n",
    "\n",
    "    # Load cleaned data to Cassandra\n",
    "    silver_table = 'silver_sales'\n",
    "    save_silver_data(session, keyspace, silver_table, silver_df)\n",
    "     # Create gold tables\n",
    "    create_gold_tables(session, keyspace, silver_table)\n",
    "\n",
    "    # Shutdown connection\n",
    "    cluster.shutdown()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "249a216d",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
